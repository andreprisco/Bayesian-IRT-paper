---
author:
  - name: Paul-Christian Bürkner
    affiliation: University of Münster
    address: >
      Fliednerstr. 21,
      48149 Münster, Germany
    email: \email{paul.buerkner@gmail.com}
    url: https://paul-buerkner.github.io/
title:
  formatted: "Bayesian Item Response Modelling in \\proglang{R} Using \\pkg{brms} and \\proglang{Stan}"
  # If you use tex in the formatted title, also supply version without
  plain:     "Bayesian Item Response Modelling in R Using brms and Stan"
  # For running headers, if needed
  short:     "Bayesian IRT Modelling Using \\pkg{brms}"
abstract: >
  Item Response Theory (IRT) is widely applied in the social sciences to model persons’ responses on a set of items measuring one or more dimensions. While several R packages have been developed that implement IRT models, they are each limited to a few sub-classes of models. Unfortunately, model specification syntax and post-processing methods are rather inconsistent across packages making it hard for users to switch between models implemented in the different packages. Further, most implementations are frequentist while the availibility of Bayesian methods remains comparably limited. We demonstrate how to use the R package brms and Stan to specify and fit a wide range of Bayesian IRT models using well known multilevel formula syntax. Further, item and person parameters can be related in both a linear or non-linear manner. Discrete, ordinal, and continuous responses are supported. Common IRT model classes of the presented framework include 1PL and 2PL logistic models optionally also containing guessing parameters, graded response and partial credit ordinal models, as well as drift diffusion models of response times coupled with binary decisions. Posterior distributions of item and person parameters can be conveniently extracted and summarized. Model fit can be evaluated and compared using Bayes factors and approximate cross-validation procedures.
keywords:
  # at least one keyword must be supplied
  formatted: [Item Response Theory, Bayesian Statistics, "\\proglang{R}",
   "\\proglang{Stan}", "\\pkg{brms}"]
  plain:     [Item Response Theory, Bayesian Statistics, R, Stan, brms]
preamble: >
  \usepackage{amsmath}
output: rticles::jss_article
bibliography: Bayesian-IRT.bib
---

# Introduction

# Model description and formula syntax

# Parameter estimation and post-processing

The \pkg{brms} package does not fit models itself but uses \pkg{Stan} [@carpenter2017] on the
back-end. Accordingly, all samplers implemented in \pkg{Stan} can be used to fit
\pkg{brms} models. The flagship algorithm of Stan is an adaptive Hamiltonian
Monte-Carlo (HMC) sampler [@betancourt2014;@betancourt2017;@stanM2019], which 
progressed from the No-U-Turn Sampler
(NUTS) by \cite{hoffman2014}. HMC-like algorithms produce posterior samples that
are much less autocorrelated than those of other samplers such as the
random-walk Metropolis algorithm \citep{hoffman2014, creutz1988}. What is more,
consequtive samples may even be anti-correlated leading to higher efficiency than
completely independent samples [@gelman2014]. The main drawback of this increased
efficiency is the need to calculate the gradient of the log-posterior, which can
be automated using algorithmic differentiation \citep{griewank2008} but is still
a time-consuming process for more complex models. Thus, using HMC leads to
higher quality samples but takes more time per sample than other algorithms
typically applied. Another drawback of HMC is the need to pre-specify at least
two parameters, which are both critical for the performance of HMC. The adaptive
HMC Sampler of Stan allows setting these parameters automatically thus
eliminating the need for any hand-tuning, while still being at least as
efficient as a well tuned HMC \citep{hoffman2014}. For more details on the
sampling algorithms applied in \pkg{Stan}, see the \pkg{Stan} user's manual
\citep{stanM2019} as well as \cite{hoffman2014}.

After the estimation of the parameters' joint posterior distribution, \pkg{brms}
offers a wide range of post-processing options of which several are helpful in
an IRT context. Below, we introduce the most important post-processing options.
We will show their usage in hands-on examples in the upcoming sections. For a
quick numerical and graphical summary, respectively, of the central model
parameters, we recommend the \code{summary} and \code{plot} methods. The
posterior distribution of person parameters (and, if also modeled as varying
effects, item parameters) can be extracted with the \code{coef} method. The
\code{hypothesis} method can be used to easily compute and evaluate parameter
contrasts, for instance, when the goal is to compare the difficulty of two items
or the ability of two persons. A visualization of the effects of item or person
covariates is readily available via the \code{marginal_effects} method.

With the help of the \code{posterior_predict} method, \pkg{brms} allows drawing
samples from the posterior predictive distribution. This not only allows to make
predictions for existing and new data, but also enables the comparison between
the actual response $y$ and the response $\hat{y}$ predicted by the model. Such
comparisons can be visualized in the form of posterior-predictive checks by
means of the \code{pp_check} method [@gabry2019]. Further, via the
\code{log_lik} method, the pointwise log-likelihood can be obtained, which can
be used, among others, for various cross-validation methods. Possibly the most
widely known cross-validation approach is leave-one-out cross-validation
[LOO-CV; @vehtari2017loo], for which an approximate version is available via the
\code{loo} method of the \pkg{loo} package [@vehtari2017loo; @vehtari2017psis]. 
If LOO-CV is not an option or if the approximation fails, exact
k-fold cross-valdiation is available via the \code{kfold} method. The
cross-validation results can be further post-processed for the purpose of
comparison, selection, or averaging of models. In these contexts, the
\code{loo_compare}, \code{model_weights}, and \code{pp_average} methods are
particularily helpful.

In addition to cross-validation based fit measures, the marginal likelihood
(i.e., the denomintor in Bayes' theorem) and marginal likelihood ratios,
commonly known as Bayes factors, can be used for model comparison,
selection, or averaging as well [@kass1995]. In general, obtaining the marginal
likelihood of a model is a computationally demanding task [@kass1995]. In \pkg{brms}
this is realized via bridgesampling [@meng1996; @meng2002] as implemented in the
\pkg{bridgesampling} package [@bridgesampling]. The corresponding methods are called
\code{bridge_sampler} to obtain (log) marginal likelihood estimates,
\code{bayes_factor} to obtain Bayes factors and \code{post_prob} to obtain
posterior model probabilities based on prior model probabilities and marginal
likelihood estimates.

# Binary Models

# Ordinal Models

# Response Times Models


# Conclusion
